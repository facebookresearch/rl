{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182c2c65",
   "metadata": {},
   "source": [
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2c125",
   "metadata": {},
   "source": [
    "TensorDict is a new tensor structure introduced in torchrl. \n",
    "\n",
    "With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. TensorDict aims at making it more convenient to deal with multiple tensors at the same time. \n",
    "\n",
    "Furthermore, different RL algorithms can deal with different input and outputs. The TensorDict allows to abstract away the differences between these algorithmes. \n",
    "\n",
    "TensorDict combines the convinience of using dicts to organize your data with the power of pytorch tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a89f7",
   "metadata": {},
   "source": [
    "#### Improving the modularity of codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a8870",
   "metadata": {},
   "source": [
    "Let's suppose we have 2 datasets: Dataset A which has images and labels and Dataset B which has images, segmentation maps and labels. \n",
    "\n",
    "We want to train 2 methods (Algo A on dataset A and algo B on dataset B) that share the same training loop. \n",
    "\n",
    "In classical pytorch we would need to do the following:\n",
    "```python\n",
    "#Method A\n",
    "for i in range(optim_steps):\n",
    "    images, labels = get_data_A()\n",
    "    loss = loss_module_A(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "````\n",
    "\n",
    "```python\n",
    "#Method B\n",
    "for i in range(optim_steps):\n",
    "    images, masks, labels = get_data_B()\n",
    "    loss = loss_module_B(images, masks, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "We can see that this limits the reusability of code. A lot of code has to be rewriten because of the modality difference between the 2 datasets.\n",
    "The idea of TensorDict is to do the following:\n",
    "```python\n",
    "# General Method\n",
    "get_data = instantiate(cfg.data)\n",
    "loss_module = instantiate(cfg.module)\n",
    "for i in range(optim_steps):\n",
    "    tensordict = get_data()\n",
    "    loss = loss_module(tensordict)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "\n",
    "Now we can reuse the same training loop for all methods that we want. We just need to make sure that <code>instantiate(cfg.data)</code> and <code>instantiate(cfg.module)</code> maps to the desired method and data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54fa30",
   "metadata": {},
   "source": [
    "#### Can't i do this with a python dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f677019",
   "metadata": {},
   "source": [
    "One could argue that you could achieve the same results with a dataset that outputs a pytorch dict. \n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "    ...\n",
    "    \n",
    "        return {\"modality_A\": torch.Tensor(torch.randn(2)), \"modality_B\": torch.Tensor(torch.randn(2))}\n",
    "    \n",
    "```\n",
    "However to achieve this you would need to write a complicated collate function that make sure that every modality is agregated properly.\n",
    "\n",
    "```python\n",
    "\n",
    "def collate_dict_fn(dict_list):\n",
    "    final_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        final_dict[key]= []\n",
    "        for single_dict in dict_list:\n",
    "            final_dict[key].append(single_dict[key])\n",
    "        final_dict[key] = torch.stack(final_dict[key], dim=0)\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_dict_fn)\n",
    "\n",
    "````\n",
    "With TensorDicts this is now much simpler:\n",
    "\n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "        ...\n",
    "    \n",
    "        return TensorDict({\"modality_A\": torch.Tensor(torch.randn(2)), \"modality_B\": torch.Tensor(torch.randn(2)), batch_size=[]})\n",
    "```\n",
    "\n",
    "\n",
    "Here, the collate function is as simple as:\n",
    "```python\n",
    "collate_tensordict_fn = lambda tds : torch.stack(tds, dim=0)\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_tensordict_fn)\n",
    "```\n",
    "This is an exemple of how TensorDict could facilitate such operations.\n",
    "\n",
    "TensorDict inherits multiple properties from torch tensors that we will detail furtherdown, which make them quite practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1c399",
   "metadata": {},
   "source": [
    "## TensorDict dictionary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14aaa07",
   "metadata": {},
   "source": [
    "TensorDict shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00c4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85250bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b37416",
   "metadata": {},
   "source": [
    "If we want to access a certain key, it is explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1340830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[\"a\"])\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6797535",
   "metadata": {},
   "source": [
    "Also works with get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a57a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict.get(\"a\"))\n",
    "print(tensordict.get(\"a\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75891945",
   "metadata": {},
   "source": [
    "#### TensorDict.keys()\n",
    "Keys can be retrieved to TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c25f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for key in tensordict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb389f9",
   "metadata": {},
   "source": [
    "#### TensorDict.values()\n",
    "The values of a TensorDict can be retrieved with the values() function. On the contrary of python dicts, the values() function return a generator and not a list for memory efficiency reasons. Indeed, python dictionnary are not designed to store tensors which can take a lot of space in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb78d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _TensorDict.values at 0x127435350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496e6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad92f9",
   "metadata": {},
   "source": [
    "#### TensorDict.set()\n",
    "The set function can be used to set new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7983bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c is set as tensor([[[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict.set(\"c\", torch.zeros((3, 4, 2, 2)))\n",
    "print(f\"c is set as {tensordict['c']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b51010",
   "metadata": {},
   "source": [
    "#### TensorDict.update()\n",
    "The update function can be used to update the dict with other dict values (Or TensorDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002ede14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "d is set as tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\":torch.ones((3, 4, 5)), \"d\":torch.ones((3, 4, 2))})\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"a is now {tensordict['a']}\")\n",
    "print(f\"d is set as {tensordict['d']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ac1b6",
   "metadata": {},
   "source": [
    "#### TensorDict del key\n",
    "TensorDict also support keys deletion with the del operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d2b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b', 'd'])\n"
     ]
    }
   ],
   "source": [
    "del tensordict[\"c\"]\n",
    "print(tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a07ee4",
   "metadata": {},
   "source": [
    "## TensorDict as a pytorch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c756e",
   "metadata": {},
   "source": [
    "But wait? Can't we do this with a classical dict? \n",
    "Well, we would like the TensorDict to keep some nice Pytorch properties. TensorDict combines the advantages of the Python dictionary and of a Pytorch Tensor.\n",
    "TensorDict has a batch size. It is not inferred automatically by looking at the tensors, but must be set when creating the TensorDict.\n",
    "\n",
    "TensorDict is a tensor container where all tensors are stored in akey-value pair fashion and where each element shares at least the following features:\n",
    "- device;\n",
    "- memory location (shared, memory-mapped array, ...);\n",
    "- batch size (i.e. n^th first dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5978eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a72121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)\n",
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a73a0",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929efaa",
   "metadata": {},
   "source": [
    "Tensor dict has a batch size which is shared across all tensors. The batch size can be [], unidimensional or multidimensional according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cca800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228d0ec",
   "metadata": {},
   "source": [
    "You cannot have items that don't share the batch size inside the same TensorDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a40031",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensordict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:356\u001b[0m, in \u001b[0;36m_TensorDict.update\u001b[0;34m(self, input_dict_or_td, clone, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clone:\n\u001b[1;32m    355\u001b[0m         value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:1646\u001b[0m, in \u001b[0;36mTensorDict.set\u001b[0;34m(self, key, value, inplace, _run_checks, _meta_val)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict \u001b[38;5;129;01mand\u001b[39;00m inplace:\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_(key, value)\n\u001b[0;32m-> 1646\u001b[0m proc_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tensor_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_shared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# check_tensor_shape=_run_checks\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict[key] \u001b[38;5;241m=\u001b[39m proc_value\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict_meta[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1654\u001b[0m     MetaTensor(\n\u001b[1;32m   1655\u001b[0m         proc_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _meta_val\n\u001b[1;32m   1661\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:480\u001b[0m, in \u001b[0;36m_TensorDict._process_tensor\u001b[0;34m(self, input, check_device, check_tensor_shape, check_shared)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_shared is not authorized anymore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_tensor_shape \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch dimension mismatch, got self.batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and tensor.shape[:self.batch_dims]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# minimum ndimension is 1\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"c\": torch.zeros(4, 3, 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict.batch_size = [4,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b1c53",
   "metadata": {},
   "source": [
    "#### Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90079564",
   "metadata": {},
   "source": [
    "TensorDict can be sent to the desired devices like a pytorch tensor with `td.cuda()` or `td.to(device)` with `device`the desired device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a19c16",
   "metadata": {},
   "source": [
    "#### Memory sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9333ff",
   "metadata": {},
   "source": [
    "When on cpu, you can use either `TensorDict.memmap_()` or `TensorDict.share_memory_()` to setup you tensor dict as a memmap or send it to shared memory resp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146d69b",
   "metadata": {},
   "source": [
    "#### Cloning\n",
    "TensorDict supports cloning. Cloning returns the same SubTensorDict item than the original item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbb6e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "tensordict_clone[\"a\"] = torch.ones(*tensordict.shape, 5)\n",
    "print(tensordict[\"a\"])\n",
    "print(tensordict_clone[\"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c791fd",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9876782",
   "metadata": {},
   "source": [
    "#### Slicing and indexing\n",
    "Slicing and indexing is supported among the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0ff66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c5aa4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ba5aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797c29b",
   "metadata": {},
   "source": [
    "#### Setting values with indexing\n",
    "We can also edit certain tensor features by deliminting certain indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf86358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]),\n",
       " tensor([[[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]],\n",
       " \n",
       "         [[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td2 = TensorDict({\"a\": torch.ones(2, 4, 5), \"b\": torch.ones(2, 4)}, batch_size=[2, 4])\n",
    "tensordict[:-1] = td2\n",
    "tensordict[\"a\"], tensordict[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436749a",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0f008",
   "metadata": {},
   "source": [
    "We can perform masking on the indexes. Mask must be a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a18e36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([6, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([6, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([6]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.Tensor([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]]).bool()\n",
    "tensordict[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09de567",
   "metadata": {},
   "source": [
    "TensorDict support other tensor operations such as torch.cat, reshape, undind(dim), view(\\*shape), squeeze(dim), unsqueeze(dim), permute(\\*dims) requiring the operations to comply with the batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e73bbb",
   "metadata": {},
   "source": [
    "#### View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a9340",
   "metadata": {},
   "source": [
    "Support for the view operation returning a `ViewedTensorDict`. Use `to_tensordict` to comeback to retrieve TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb7e6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViewedTensorDict(\n",
       "\tsource=TensorDict(\n",
       "\t    fields={\n",
       "\t        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
       "\t        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
       "\t    batch_size=torch.Size([3, 4]),\n",
       "\t    device=cpu,\n",
       "\t    is_shared=False), \n",
       "\top=view(size=torch.Size([-1])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31b3b7",
   "metadata": {},
   "source": [
    "#### Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8329a908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutedTensorDict(\n",
       "\tsource=TensorDict(\n",
       "\t    fields={\n",
       "\t        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
       "\t        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
       "\t    batch_size=torch.Size([3, 4]),\n",
       "\t    device=cpu,\n",
       "\t    is_shared=False), \n",
       "\top=permute(dims=(1, 0)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.permute(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48979edd",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "Reshape allows reshaping the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a3871109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d650b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorDict(\n",
       "     fields={\n",
       "         a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "         b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "     batch_size=torch.Size([4]),\n",
       "     device=cpu,\n",
       "     is_shared=False),\n",
       " TensorDict(\n",
       "     fields={\n",
       "         a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "         b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "     batch_size=torch.Size([4]),\n",
       "     device=cpu,\n",
       "     is_shared=False),\n",
       " TensorDict(\n",
       "     fields={\n",
       "         a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "         b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "     batch_size=torch.Size([4]),\n",
       "     device=cpu,\n",
       "     is_shared=False))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7a6e55",
   "metadata": {},
   "source": [
    "#### Unbind and Cat\n",
    "TensorDict can unbind and cat among a dim over the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2480deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([4]),\n",
      "    device=cpu,\n",
      "    is_shared=False), TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([4]),\n",
      "    device=cpu,\n",
      "    is_shared=False), TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([4]),\n",
      "    device=cpu,\n",
      "    is_shared=False))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cat\n",
    "list_tensordict = tensordict.unbind(0)\n",
    "print(list_tensordict)\n",
    "torch.cat(list_tensordict, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78381ee8",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "Tensordict also supports squeeze and unsqueeze. Use `to_tensordict` to retrieve a tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a38f2b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([1, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([1, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([1, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(tensordict.unsqueeze(0).to_tensordict())\n",
    "print(tensordict.squeeze(0).to_tensordict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e845f",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593343a",
   "metadata": {},
   "source": [
    "TensorDict supports stacking, stacking is done in a lazy fashion, returning a LazyStackedTensorDict item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01075269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyStackedTensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "every tensordict is awesome!\n"
     ]
    }
   ],
   "source": [
    "#Stack\n",
    "staked_tensordict = torch.stack([tensordict, tensordict.clone()], dim=0)\n",
    "print(staked_tensordict)\n",
    "if staked_tensordict[0] is tensordict:\n",
    "    print(\"every tensordict is awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba554281",
   "metadata": {},
   "source": [
    "If we want to have a contiguous tensordict, we can call `.to_tensordict()` or `.contiguous()`. It is recommended to perform this operation before accessing the values of the stacked tensordict for efficiency purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f546995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(staked_tensordict.contiguous())\n",
    "print(staked_tensordict.to_tensordict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea6285",
   "metadata": {},
   "source": [
    "## How to use them in practice? The tensor the TensorDictModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb76da1",
   "metadata": {},
   "source": [
    "Now that we have seen the TensorDict object, how do we use it in pratice? We introduce the TensorDictModule. The TensorDictModule is an nn.Module that takes a TensorDict in his forward method. The user defines the keys that the module will take as an input and write the output in the same TensorDict at a given set of key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5424b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import TensorDictModule\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff8307",
   "metadata": {},
   "source": [
    "### Example: Simple Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bfc04",
   "metadata": {},
   "source": [
    "Let's imagine we have 2 entries Tensor dict, a and b and we only want to affect a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c45b16aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        a_out: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.randn(5, 3), \"b\": torch.randn(5, 4, 3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3, 10),in_keys=[\"a\"], out_keys=[\"a_out\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cad800",
   "metadata": {},
   "source": [
    "We can also do it inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d18be016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5, 3), \"b\":torch.randn(5, 4, 3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3, 10),in_keys=[\"a\"], out_keys=[\"a\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269f1d3",
   "metadata": {},
   "source": [
    "### Example: 2 input merging with 2 linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1f6d0",
   "metadata": {},
   "source": [
    "Now lets imagine a more complex network that takes 2 entries and average them into a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfcdec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeLinear(nn.Module):\n",
    "    def __init__(self, in_1, in_2, out):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out)\n",
    "        self.linear_2  = nn.Linear(in_2,out)\n",
    "    def forward(self, x_1, x_2):\n",
    "        return (self.linear_1(x_1) + self.linear_2(x_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9183ab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        c: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3), \"c\":torch.randn(5,4)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MergeLinear(3, 4, 10),in_keys=[\"a\",\"c\"], out_keys=[\"output\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b9214",
   "metadata": {},
   "source": [
    "### Example: 1 input to 2 outputs linear layer\n",
    "We can also map to multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9fccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLinear(nn.Module):\n",
    "    def __init__(self, in_1, out_1, out_2):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out_1)\n",
    "        self.linear_2  = nn.Linear(in_1,out_2)\n",
    "    def forward(self, x):\n",
    "        return self.linear_1(x), self.linear_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd5a891f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        output_1: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output_2: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MultiHeadLinear(3, 4, 10),in_keys=[\"a\"], out_keys=[\"output_1\", \"output_2\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a2ec1",
   "metadata": {},
   "source": [
    "As we shown previously, the TensorDictModule can take any nn.Module and perform the operations inside a TensorDict. When having multiple input keys and output keys, make sure they match the order in the module.\n",
    "The tensordictmodule allows to use only the tensors that we want and keep the output inside the same object. It can even perform the operations inplace by setting the output key to be the same as an already set key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d459c",
   "metadata": {},
   "source": [
    "### Example: A transformer with TensorDict?\n",
    "Let's attempt to create a transformer with TensorDict and TensorDictModule\n",
    "\n",
    "Disclaimer: This implementation don't claim to be \"better\" than a classical tensor-based implementation. It is just meant to showcase the TensorDictModule features.\n",
    "For simplicity we will not have positional encoders.\n",
    "\n",
    "Let's first implement the classical transformers blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80f2ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokensToQKV(nn.Module):\n",
    "    def __init__(self, to_dim, from_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(to_dim, latent_dim)\n",
    "        self.k = nn.Linear(from_dim, latent_dim)\n",
    "        self.v = nn.Linear(from_dim, latent_dim)\n",
    "    def forward(self, X_to, X_from):\n",
    "        Q = self.q(X_to)\n",
    "        K = self.k(X_from)\n",
    "        V = self.v(X_from)\n",
    "        return Q, K, V\n",
    "\n",
    "class SplitHeads(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, to_num, latent_dim = Q.shape\n",
    "        _, from_num, _ = K.shape\n",
    "        d_tensor = latent_dim // self.num_heads\n",
    "        Q = Q.reshape(batch_size, to_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        K = K.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        V = V.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        return Q, K, V\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, latent_dim, to_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(latent_dim, to_dim)\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, n_heads, to_num, d_in = Q.shape\n",
    "        attn = self.softmax(Q @ K.transpose(2,3) / d_in)\n",
    "        out = attn @ V\n",
    "        out = self.out(out.transpose(1, 2).reshape(batch_size, to_num, n_heads*d_in))\n",
    "        return out, attn\n",
    "class SkipLayerNorm(nn.Module):\n",
    "    def __init__(self, to_len, to_dim):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((to_len, to_dim))\n",
    "    def forward(self, x_0, x_1):\n",
    "        return self.layer_norm(x_0+x_1)\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, to_dim, hidden_dim, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(to_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, to_dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.FFN(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98188b17",
   "metadata": {},
   "source": [
    "Now, we can build the TransformerBlock thanks to the TensorDictModule. Since the changes affect the tensor dict, we just need to map outputs to the right name such as it is picked up by the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a88bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockTensorDict(nn.Module):\n",
    "    def __init__(self, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer_block = nn.Sequential(\n",
    "            TensorDictModule(TokensToQKV(to_dim, from_dim, latent_dim), in_keys=[to_name, from_name], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(SplitHeads(num_heads), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(Attention(latent_dim, to_dim), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"X_out\",\"Attn\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "            TensorDictModule(FFN(to_dim, 4*to_dim), in_keys=[\"X_to\"], out_keys=[\"X_out\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "        )\n",
    "    def forward(self, X_tensor_dict):\n",
    "        self.transformer_block(X_tensor_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15ea7d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        Attn: Tensor(torch.Size([8, 2, 3, 10]), dtype=torch.float32),\n",
       "        K: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        Q: Tensor(torch.Size([8, 2, 3, 5]), dtype=torch.float32),\n",
       "        V: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        X_from: Tensor(torch.Size([8, 10, 6]), dtype=torch.float32),\n",
       "        X_out: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32),\n",
       "        X_to: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "transformer_block = TransformerBlockTensorDict(\"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_block(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960bbd6",
   "metadata": {},
   "source": [
    "The output of the transformer layer can now be found at tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "858f205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8713, -1.2626,  1.3218, -0.2947,  1.6938],\n",
       "         [-0.7374, -0.6038, -1.4958, -0.3975,  0.0741],\n",
       "         [-0.5026,  0.0095,  1.8102,  0.2308,  1.0256]],\n",
       "\n",
       "        [[ 0.4484,  0.0689,  1.0152, -1.1690,  1.2264],\n",
       "         [-0.5891,  0.0737,  0.7038,  1.0404,  0.0131],\n",
       "         [ 1.0050, -2.4708, -0.7890, -1.0160,  0.4391]],\n",
       "\n",
       "        [[-1.8364, -0.5181, -0.5258,  0.5166,  1.8120],\n",
       "         [ 1.3389,  0.1451, -0.1267, -0.7637,  1.6104],\n",
       "         [-0.1859, -0.4134, -1.4359, -0.1131,  0.4961]],\n",
       "\n",
       "        [[-1.0511,  0.1636, -0.9440, -0.2152, -0.4874],\n",
       "         [ 1.4676,  2.0405,  0.2846,  0.5990,  1.0199],\n",
       "         [-1.5073,  0.0980, -1.5943, -0.1160,  0.2421]],\n",
       "\n",
       "        [[-0.6059,  0.3442,  0.6854, -0.0933,  1.8850],\n",
       "         [-0.2040, -2.0479,  0.8991,  1.1162,  0.0855],\n",
       "         [-1.6792, -0.4797,  0.4558,  0.4763, -0.8374]],\n",
       "\n",
       "        [[-1.2463, -1.3887,  1.2930,  0.5651,  0.9994],\n",
       "         [-0.1023, -0.4523, -2.0760,  1.6500,  0.5962],\n",
       "         [ 0.7221,  0.1171,  0.1437, -0.2839, -0.5374]],\n",
       "\n",
       "        [[-0.3637, -1.2232, -2.0972, -0.7830, -0.1663],\n",
       "         [-0.5369,  0.0789, -0.9869,  0.6352,  1.5502],\n",
       "         [ 0.3313,  0.2594,  1.5771,  0.6336,  1.0914]],\n",
       "\n",
       "        [[-1.0102,  0.4594,  0.5603,  0.1587,  0.2164],\n",
       "         [-1.3799, -0.1682, -1.9153,  0.9154,  1.8860],\n",
       "         [-0.0694, -0.8951, -0.6851,  0.6067,  1.3203]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a09de",
   "metadata": {},
   "source": [
    "We can now create a transformer easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a48be821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTensorDict(nn.Module):\n",
    "    def __init__(self, num_blocks, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.ModuleList([TransformerBlockTensorDict(to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads) for _ in range(num_blocks)])\n",
    "    def forward(self, X_tensor_dict):\n",
    "        for transformer_block in self.transformer:\n",
    "            transformer_block(X_tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e749bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d4062",
   "metadata": {},
   "source": [
    "For an encoder, we just need to take the same tokens for both queries, keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c02bf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.0456e-01,  6.2688e-01, -1.1026e+00,  2.2786e-02, -4.8655e-02],\n",
       "         [-9.7513e-01,  1.4375e+00,  9.4504e-01,  2.0078e+00, -8.5485e-01],\n",
       "         [-1.3192e+00,  8.7940e-01, -1.2088e+00,  4.6428e-01, -1.7003e-01]],\n",
       "\n",
       "        [[-2.4683e+00,  1.1900e+00, -4.6999e-01,  8.1202e-01, -1.0019e+00],\n",
       "         [ 9.6744e-01,  1.0676e+00,  1.0292e+00,  4.7986e-01, -1.2177e+00],\n",
       "         [ 3.2124e-02,  4.6237e-01, -7.1896e-01,  2.0720e-03, -1.6574e-01]],\n",
       "\n",
       "        [[-2.2703e-01,  1.5631e+00,  1.1274e+00,  8.1163e-02, -1.5204e+00],\n",
       "         [-1.8939e+00,  7.4907e-01, -1.6144e+00,  7.3381e-01,  7.8596e-01],\n",
       "         [-7.7463e-02,  2.4682e-01,  4.6115e-01,  3.5791e-01, -7.7312e-01]],\n",
       "\n",
       "        [[ 4.2789e-01,  7.7004e-02, -5.2232e-01, -1.3905e+00, -6.8685e-01],\n",
       "         [-9.8940e-01,  6.9261e-02,  1.8176e+00,  1.2323e+00, -2.8591e-01],\n",
       "         [-1.9008e+00,  1.2424e+00,  9.0587e-01,  3.6788e-01, -3.6444e-01]],\n",
       "\n",
       "        [[ 1.4538e+00,  4.6922e-01, -8.1502e-01, -3.0426e-01,  3.3914e-01],\n",
       "         [ 4.5448e-02,  5.8241e-01, -5.1411e-02,  2.1194e-01, -3.5672e-01],\n",
       "         [-2.6675e+00,  1.0907e+00,  9.3493e-01,  4.4590e-01, -1.3785e+00]],\n",
       "\n",
       "        [[-8.6485e-01,  1.1146e+00, -9.4181e-02, -1.1407e-01,  6.2847e-01],\n",
       "         [-9.5162e-01,  1.4542e+00,  1.2157e-02, -2.0240e-01, -1.5317e+00],\n",
       "         [-9.3001e-01,  9.8748e-01,  9.6898e-01,  1.2264e+00, -1.7035e+00]],\n",
       "\n",
       "        [[ 1.8318e-01,  8.8817e-01, -4.1605e-01, -7.2077e-02,  1.0248e+00],\n",
       "         [ 1.1950e+00, -3.1990e-01, -3.0087e+00, -8.1052e-01,  4.2547e-01],\n",
       "         [ 4.8264e-02,  8.2594e-01, -4.8231e-01, -2.2883e-01,  7.4760e-01]],\n",
       "\n",
       "        [[-2.0185e+00,  2.7137e-01,  1.9260e-01, -3.7461e-01, -1.4131e+00],\n",
       "         [ 3.0497e-01,  4.7218e-01,  1.4051e+00, -7.2168e-01, -7.7026e-01],\n",
       "         [ 1.3967e+00, -6.0792e-01,  1.1108e-01,  1.7145e+00,  3.7664e-02]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder = TransformerTensorDict(6, \"X_to\", \"X_to\", to_dim, to_len, to_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_encoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a19b6",
   "metadata": {},
   "source": [
    "For a decoder, we now can extract info from X_from into X_to. X_to will map to queries whereas X_from will map to keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec28da52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3380,  0.7571, -1.0049,  0.7433, -0.1268],\n",
       "         [-1.2908,  1.1133, -0.1441,  1.9060, -1.1740],\n",
       "         [-1.2169,  1.1862, -0.9880,  0.9077, -0.3301]],\n",
       "\n",
       "        [[-0.9989,  1.0225,  0.0516,  1.4268, -1.3924],\n",
       "         [-0.4546,  1.6237, -0.9002,  1.0320, -1.1606],\n",
       "         [-0.5801,  0.9752, -1.1864,  0.4610,  0.0803]],\n",
       "\n",
       "        [[-0.9055,  1.3019, -0.1604,  1.2191, -1.8533],\n",
       "         [-1.2209,  1.0449, -0.6953,  1.0392,  0.4056],\n",
       "         [-0.3828,  0.6094,  0.0309,  0.9272, -1.3600]],\n",
       "\n",
       "        [[-0.3067,  0.0189, -0.9604, -0.3966, -0.3716],\n",
       "         [-1.0679,  0.4198,  1.2470,  1.9662, -0.8475],\n",
       "         [-1.6165,  1.1001, -0.3376,  1.4791, -0.3264]],\n",
       "\n",
       "        [[-0.0980,  0.6583, -1.2214,  0.2261, -0.4485],\n",
       "         [-0.6073,  1.5547, -0.3092,  1.1512, -1.0601],\n",
       "         [-1.4279,  1.2677,  0.1266,  1.4727, -1.2850]],\n",
       "\n",
       "        [[-0.4164,  0.7499,  0.2536,  0.1846,  0.1112],\n",
       "         [-0.4129,  1.0208, -0.3762,  0.7487, -1.3215],\n",
       "         [-0.1598,  0.5029, -0.3288,  1.9525, -2.5087]],\n",
       "\n",
       "        [[-0.3682,  0.8304, -0.8471,  0.5485,  0.4438],\n",
       "         [-0.8762,  1.1699, -2.6552,  0.4682,  0.1896],\n",
       "         [-0.3391,  1.0842, -1.0764,  0.5564,  0.8712]],\n",
       "\n",
       "        [[-1.0284,  0.3804,  0.4793,  0.4096, -2.1200],\n",
       "         [-0.2695,  1.0064, -0.2066,  0.1593, -0.7439],\n",
       "         [ 0.9516,  0.8927, -0.9734,  1.9427, -0.8802]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder = TransformerTensorDict(6, \"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_decoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e1d61",
   "metadata": {},
   "source": [
    "Now we can look at both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c270fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca1e26ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8bd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
