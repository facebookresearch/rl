{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0174624",
   "metadata": {},
   "source": [
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b8238",
   "metadata": {},
   "source": [
    "`TensorDict` is a new tensor structure introduced in TorchRL. \n",
    "\n",
    "With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. `TensorDict` aims at making it more convenient to deal with multiple tensors at the same time. \n",
    "\n",
    "Furthermore, different RL algorithms can deal with different input and outputs. The `TensorDict` class makes it possible to abstract away the differences between these algorithmes. \n",
    "\n",
    "TensorDict combines the convinience of using `dict`s to organize your data with the power of pytorch tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adeede6",
   "metadata": {},
   "source": [
    "#### Improving the modularity of codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11d7f7",
   "metadata": {},
   "source": [
    "Let's suppose we have 2 datasets: Dataset A which has images and labels and Dataset B which has images, segmentation maps and labels. \n",
    "\n",
    "Suppose we want to train a common algorithm over these two datasets (i.e. an algorithm that would ignore the mask or infer it when needed). \n",
    "\n",
    "In classical pytorch we would need to do the following:\n",
    "```python\n",
    "#Method A\n",
    "for i in range(optim_steps):\n",
    "    images, labels = get_data_A()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "````\n",
    "\n",
    "```python\n",
    "#Method B\n",
    "for i in range(optim_steps):\n",
    "    images, masks, labels = get_data_B()\n",
    "    loss = loss_module(images, labels)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "We can see that this limits the reusability of code. A lot of code has to be rewriten because of the modality difference between the 2 datasets.\n",
    "The idea of TensorDict is to do the following:\n",
    "\n",
    "```python\n",
    "# General Method\n",
    "for i in range(optim_steps):\n",
    "    tensordict = get_data()\n",
    "    loss = loss_module(tensordict)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "```\n",
    "\n",
    "\n",
    "Now we can reuse the same training loop across datasets and losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d128d7c",
   "metadata": {},
   "source": [
    "#### Can't i do this with a python dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2536a",
   "metadata": {},
   "source": [
    "One could argue that you could achieve the same results with a dataset that outputs a pytorch dict. \n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "    ...\n",
    "    \n",
    "        return {\"modality_A\": torch.Tensor(torch.randn(2)), \"modality_B\": torch.Tensor(torch.randn(2))}\n",
    "    \n",
    "```\n",
    "\n",
    "However to achieve this you would need to write a complicated collate function that make sure that every modality is agregated properly.\n",
    "\n",
    "```python\n",
    "\n",
    "def collate_dict_fn(dict_list):\n",
    "    final_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        final_dict[key]= []\n",
    "        for single_dict in dict_list:\n",
    "            final_dict[key].append(single_dict[key])\n",
    "        final_dict[key] = torch.stack(final_dict[key], dim=0)\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_dict_fn)\n",
    "\n",
    "````\n",
    "With TensorDicts this is now much simpler:\n",
    "\n",
    "```python\n",
    "class DictDataset(Dataset):\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx)\n",
    "        \n",
    "        ...\n",
    "    \n",
    "        return TensorDict({\"modality_A\": torch.Tensor(torch.randn(2)), \"modality_B\": torch.Tensor(torch.randn(2)), batch_size=[]})\n",
    "```\n",
    "\n",
    "\n",
    "Here, the collate function is as simple as:\n",
    "```python\n",
    "collate_tensordict_fn = lambda tds : torch.stack(tds, dim=0)\n",
    "\n",
    "dataloader = Dataloader(DictDataset(), collate_fn = collate_tensordict_fn)\n",
    "```\n",
    "\n",
    "TensorDict inherits multiple properties from `torch.Tensor` and `dict` that we will detail furtherdown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1303de8",
   "metadata": {},
   "source": [
    "## `TensorDict` dictionary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79458114",
   "metadata": {},
   "source": [
    "`TensorDict` shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a39ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4009045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3, 4, 5)\n",
    "b = torch.zeros(3, 4)\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f543f6c",
   "metadata": {},
   "source": [
    "### `get(key)`\n",
    "If we want to access a certain key, we can index the tensordict or alternatively use the `get` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0235a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[\"a\"] is tensordict.get(\"a\") is a)\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9df67-8834-4a75-8e19-6be21322c8a5",
   "metadata": {},
   "source": [
    "The `get` method also supports default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6638e51-628e-4bb1-b106-989b2b8c34be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tensordict.get(\"foo\", torch.ones(3))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8db3b3-a9c1-4ba4-8c42-dd346c8fcbdd",
   "metadata": {},
   "source": [
    "## `set(key, value)`\n",
    "The `set()` method can be used to set new values. Regular indexing also does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853e0b14-a8e6-4c29-ad98-1226a21c2ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td[\"c\"] is c: True\n",
      "td[\"d\"] is d: True\n"
     ]
    }
   ],
   "source": [
    "c = torch.zeros((3, 4, 2, 2))\n",
    "tensordict.set(\"c\", c)\n",
    "print(f\"td[\\\"c\\\"] is c: {c is tensordict['c']}\")\n",
    "\n",
    "d = torch.zeros((3, 4, 2, 2))\n",
    "tensordict[\"d\"] = d\n",
    "print(f\"td[\\\"d\\\"] is d: {d is tensordict['d']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f200416",
   "metadata": {},
   "source": [
    "## Other methods:\n",
    "### `keys`\n",
    "We can access the keys of a tensordict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9882c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for key in tensordict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecc00f",
   "metadata": {},
   "source": [
    "### `values`\n",
    "The values of a `TensorDict` can be retrieved with the `values()` function. Note that, unlike python `dict`s, the `values()` method returns a generator and not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd21818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e59abc",
   "metadata": {},
   "source": [
    "### TensorDict.update()\n",
    "The `update` method can be used to update a TensorDict with another one (or with a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f216bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now equal to 1: True\n",
      "d is now equal to 2: True\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\": torch.ones((3, 4, 5)), \"d\": 2*torch.ones((3, 4, 2))})\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"a is now equal to 1: {(tensordict['a'] == 1).all()}\")\n",
    "print(f\"d is now equal to 2: {(tensordict['d'] == 2).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb8632",
   "metadata": {},
   "source": [
    "### TensorDict del key\n",
    "TensorDict also support keys deletion with the `del` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7afc943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b', 'd'])\n"
     ]
    }
   ],
   "source": [
    "del tensordict[\"c\"]\n",
    "print(tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb04f41",
   "metadata": {},
   "source": [
    "## TensorDict as a Tensor-like object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c834589",
   "metadata": {},
   "source": [
    "But wait? Can't we do this with a classical dict? \n",
    "Well, we would like the TensorDict to keep some nice Pytorch properties. TensorDict combines the advantages of the Python dictionary and of a Pytorch Tensor.\n",
    "TensorDict has a batch size. It is not inferred automatically by looking at the tensors, but must be set when creating the TensorDict.\n",
    "\n",
    "TensorDict is a tensor container where all tensors are stored in akey-value pair fashion and where each element shares at least the following features:\n",
    "- device;\n",
    "- memory location (shared, memory-mapped array, ...);\n",
    "- batch size (i.e. n^th first dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f22d4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daaa4e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2e7cd",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17d8b4",
   "metadata": {},
   "source": [
    "Tensor dict has a batch size which is shared across all tensors. The batch size can be [], unidimensional or multidimensional according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0217e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9c6aa",
   "metadata": {},
   "source": [
    "You cannot have items that don't share the batch size inside the same TensorDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08b9d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# we cannot add tensors that violate the batch size:\n",
    "try:\n",
    "    tensordict.update({\"c\": torch.zeros(4, 3, 1)})\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ec89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caramba! We got this error: the tensor a has shape torch.Size([3, 4, 5]) which is incompatible with the new shape torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# If we reset the batch size, it has to comply with the tensordict batch size\n",
    "try:\n",
    "    tensordict.batch_size = [4,4]\n",
    "except RuntimeError as err:\n",
    "    print(f\"Caramba! We got this error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba3948",
   "metadata": {},
   "source": [
    "#### Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efa0f5",
   "metadata": {},
   "source": [
    "### Device\n",
    "TensorDict can be sent to the desired devices like a pytorch tensor with `td.cuda()` or `td.to(device)` with `device`the desired device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c9d12",
   "metadata": {},
   "source": [
    "### Memory sharing via physical memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd540505",
   "metadata": {},
   "source": [
    "When on cpu, one can use either `tensordict.memmap_()` or `tensordict.share_memory_()` to send a `tensordict` to represent it as a memory-mapped collection of tensors or put it in shared memory resp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71180a",
   "metadata": {},
   "source": [
    "### Cloning\n",
    "TensorDict supports cloning. Cloning returns the same SubTensorDict item than the original item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c88f387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redefining a tensor in the clone does not impact the original tensordict:  tensor(False)\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "tensordict_clone[\"a\"] = torch.ones(*tensordict.shape, 5)\n",
    "print(\"redefining a tensor in the clone does not impact the original tensordict: \", (tensordict[\"a\"] == tensordict_clone[\"a\"]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251e116",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8159df",
   "metadata": {},
   "source": [
    "### Slicing and indexing\n",
    "Slicing and indexing is supported along the batch dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8409cfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af1387cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7133060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d84a1",
   "metadata": {},
   "source": [
    "#### Setting values with indexing\n",
    "We can also edit certain tensor features by deliminting certain indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9a2a860-e9c3-4112-9ae3-d6ba5b8473f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtd = tensordict[:, torch.tensor([1, 3])]  # a SubTensorDict keeps track of the original one: it does not create a copy in memory of the original data\n",
    "tensordict.fill_(\"a\", -1)\n",
    "assert (subtd[\"a\"] == -1).all()  # the \"a\" key-value pair has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f235ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1.]]]),\n",
       " tensor([[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td2 = TensorDict({\"a\": torch.zeros(2, 4, 5), \"b\": torch.zeros(2, 4)}, batch_size=[2, 4])\n",
    "tensordict[:-1] = td2\n",
    "tensordict[\"a\"], tensordict[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523aa6d-42ff-4fa1-9cc2-ea778aa1bc1b",
   "metadata": {},
   "source": [
    "We can set values easily just by indexing the tensordict:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148a34a",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c2075f",
   "metadata": {},
   "source": [
    "### Masking\n",
    "We can perform masking on the indexes. Mask must be a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c6bf5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([6, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([6, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([6]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.Tensor([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]]).bool()\n",
    "tensordict[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9835c39",
   "metadata": {},
   "source": [
    "TensorDict support other tensor operations such as torch.cat, reshape, undind(dim), view(\\*shape), squeeze(dim), unsqueeze(dim), permute(\\*dims) requiring the operations to comply with the batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec195a",
   "metadata": {},
   "source": [
    "### View\n",
    "Support for the view operation returning a `ViewedTensorDict`. Use `to_tensordict` to comeback to retrieve TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d909b9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViewedTensorDict(\n",
       "\tsource=TensorDict(\n",
       "\t    fields={\n",
       "\t        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
       "\t        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
       "\t    batch_size=torch.Size([3, 4]),\n",
       "\t    device=cpu,\n",
       "\t    is_shared=False), \n",
       "\top=view(size=torch.Size([-1])))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6665c",
   "metadata": {},
   "source": [
    "#### Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1774e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutedTensorDict(\n",
       "\tsource=TensorDict(\n",
       "\t    fields={\n",
       "\t        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
       "\t        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
       "\t    batch_size=torch.Size([3, 4]),\n",
       "\t    device=cpu,\n",
       "\t    is_shared=False), \n",
       "\top=permute(dims=(1, 0)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.permute(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c354e",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "Reshape allows reshaping the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9b3ab59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48933b38",
   "metadata": {},
   "source": [
    "#### Unbind and Cat\n",
    "TensorDict can unbind and cat among a dim over the tensordict batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68e8975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cat\n",
    "list_tensordict = tensordict.unbind(0)\n",
    "torch.cat(list_tensordict, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a3f68",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "Tensordict also supports squeeze and unsqueeze. Use `to_tensordict` to retrieve a tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c3a54a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([1, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([1, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([1, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(tensordict.unsqueeze(0).to_tensordict())\n",
    "print(tensordict.squeeze(0).to_tensordict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb1bc0",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dff375",
   "metadata": {},
   "source": [
    "TensorDict supports stacking, stacking is done in a lazy fashion, returning a LazyStackedTensorDict item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f90e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyStackedTensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([2, 3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([2, 3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([2, 3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "#Stack\n",
    "staked_tensordict = torch.stack([tensordict, tensordict.clone()], dim=0)\n",
    "print(staked_tensordict)\n",
    "if staked_tensordict[0] is tensordict and staked_tensordict[0] is not tensordict:\n",
    "    print(\"every tensordict is awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22161bd3",
   "metadata": {},
   "source": [
    "If we want to have a contiguous tensordict, we can call `.to_tensordict()` or `.contiguous()`. It is recommended to perform this operation before accessing the values of the stacked tensordict for efficiency purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8c66c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(staked_tensordict.contiguous(), TensorDict)\n",
    "assert isinstance(staked_tensordict.to_tensordict(), TensorDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86afd08",
   "metadata": {},
   "source": [
    "## How to use them in practice? The tensor the TensorDictModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78192367",
   "metadata": {},
   "source": [
    "Now that we have seen the TensorDict object, how do we use it in pratice? We introduce the TensorDictModule. The TensorDictModule is an nn.Module that takes a TensorDict in his forward method. The user defines the keys that the module will take as an input and write the output in the same TensorDict at a given set of key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a9c34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import TensorDictModule\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198427a",
   "metadata": {},
   "source": [
    "### Example: Simple Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9286f32",
   "metadata": {},
   "source": [
    "Let's imagine we have 2 entries Tensor dict, a and b and we only want to affect a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f42fd847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        a_out: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.randn(5, 3), \"b\": torch.randn(5, 4, 3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3, 10),in_keys=[\"a\"], out_keys=[\"a_out\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1452e41",
   "metadata": {},
   "source": [
    "We can also do it inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2e6db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5, 3), \"b\":torch.randn(5, 4, 3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3, 10),in_keys=[\"a\"], out_keys=[\"a\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbae8ef",
   "metadata": {},
   "source": [
    "### Example: 2 input merging with 2 linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c36399",
   "metadata": {},
   "source": [
    "Now lets imagine a more complex network that takes 2 entries and average them into a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4692e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeLinear(nn.Module):\n",
    "    def __init__(self, in_1, in_2, out):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out)\n",
    "        self.linear_2  = nn.Linear(in_2,out)\n",
    "    def forward(self, x_1, x_2):\n",
    "        return (self.linear_1(x_1) + self.linear_2(x_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55f66f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        c: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3), \"c\":torch.randn(5,4)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MergeLinear(3, 4, 10),in_keys=[\"a\",\"c\"], out_keys=[\"output\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b043e",
   "metadata": {},
   "source": [
    "### Example: 1 input to 2 outputs linear layer\n",
    "We can also map to multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3dc55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLinear(nn.Module):\n",
    "    def __init__(self, in_1, out_1, out_2):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out_1)\n",
    "        self.linear_2  = nn.Linear(in_1,out_2)\n",
    "    def forward(self, x):\n",
    "        return self.linear_1(x), self.linear_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52fc40c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        output_1: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output_2: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MultiHeadLinear(3, 4, 10),in_keys=[\"a\"], out_keys=[\"output_1\", \"output_2\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b756d",
   "metadata": {},
   "source": [
    "As we shown previously, the TensorDictModule can take any nn.Module and perform the operations inside a TensorDict. When having multiple input keys and output keys, make sure they match the order in the module.\n",
    "The tensordictmodule allows to use only the tensors that we want and keep the output inside the same object. It can even perform the operations inplace by setting the output key to be the same as an already set key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a7533",
   "metadata": {},
   "source": [
    "### Example: A transformer with TensorDict?\n",
    "Let's attempt to create a transformer with TensorDict and TensorDictModule\n",
    "\n",
    "Disclaimer: This implementation don't claim to be \"better\" than a classical tensor-based implementation. It is just meant to showcase the TensorDictModule features.\n",
    "For simplicity we will not have positional encoders.\n",
    "\n",
    "Let's first implement the classical transformers blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05e6a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokensToQKV(nn.Module):\n",
    "    def __init__(self, to_dim, from_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(to_dim, latent_dim)\n",
    "        self.k = nn.Linear(from_dim, latent_dim)\n",
    "        self.v = nn.Linear(from_dim, latent_dim)\n",
    "    def forward(self, X_to, X_from):\n",
    "        Q = self.q(X_to)\n",
    "        K = self.k(X_from)\n",
    "        V = self.v(X_from)\n",
    "        return Q, K, V\n",
    "\n",
    "class SplitHeads(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, to_num, latent_dim = Q.shape\n",
    "        _, from_num, _ = K.shape\n",
    "        d_tensor = latent_dim // self.num_heads\n",
    "        Q = Q.reshape(batch_size, to_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        K = K.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        V = V.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        return Q, K, V\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, latent_dim, to_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(latent_dim, to_dim)\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, n_heads, to_num, d_in = Q.shape\n",
    "        attn = self.softmax(Q @ K.transpose(2,3) / d_in)\n",
    "        out = attn @ V\n",
    "        out = self.out(out.transpose(1, 2).reshape(batch_size, to_num, n_heads*d_in))\n",
    "        return out, attn\n",
    "class SkipLayerNorm(nn.Module):\n",
    "    def __init__(self, to_len, to_dim):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((to_len, to_dim))\n",
    "    def forward(self, x_0, x_1):\n",
    "        return self.layer_norm(x_0+x_1)\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, to_dim, hidden_dim, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(to_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, to_dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.FFN(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5086060",
   "metadata": {},
   "source": [
    "Now, we can build the TransformerBlock thanks to the TensorDictModule. Since the changes affect the tensor dict, we just need to map outputs to the right name such as it is picked up by the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3f130d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockTensorDict(nn.Module):\n",
    "    def __init__(self, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer_block = nn.Sequential(\n",
    "            TensorDictModule(TokensToQKV(to_dim, from_dim, latent_dim), in_keys=[to_name, from_name], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(SplitHeads(num_heads), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(Attention(latent_dim, to_dim), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"X_out\",\"Attn\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "            TensorDictModule(FFN(to_dim, 4*to_dim), in_keys=[\"X_to\"], out_keys=[\"X_out\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "        )\n",
    "    def forward(self, X_tensor_dict):\n",
    "        self.transformer_block(X_tensor_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2d2a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        Attn: Tensor(torch.Size([8, 2, 3, 10]), dtype=torch.float32),\n",
       "        K: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        Q: Tensor(torch.Size([8, 2, 3, 5]), dtype=torch.float32),\n",
       "        V: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        X_from: Tensor(torch.Size([8, 10, 6]), dtype=torch.float32),\n",
       "        X_out: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32),\n",
       "        X_to: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "transformer_block = TransformerBlockTensorDict(\"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_block(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513287f",
   "metadata": {},
   "source": [
    "The output of the transformer layer can now be found at tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d58f4d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3948,  0.9014, -0.3433,  0.7251, -1.0122],\n",
       "         [ 0.1403,  1.2825, -1.2302, -1.4635,  0.7165],\n",
       "         [ 0.8251, -1.5065, -1.0976, -0.0920,  0.7596]],\n",
       "\n",
       "        [[ 1.5074, -0.4161,  0.5480,  1.1882, -1.3595],\n",
       "         [ 0.4081, -0.2427,  1.0663,  1.1888, -1.2557],\n",
       "         [ 0.1856, -0.5556, -1.4885,  0.5571, -1.3313]],\n",
       "\n",
       "        [[-0.1015, -1.1877, -0.1132, -0.9613, -0.7382],\n",
       "         [-0.9579,  1.7701,  1.8217,  0.5509, -0.6816],\n",
       "         [ 1.6410,  0.2096, -0.6056, -0.8921,  0.2459]],\n",
       "\n",
       "        [[-0.3648,  0.2833,  0.2137,  0.8552, -0.9622],\n",
       "         [ 0.3903, -1.2456, -0.6480, -0.4978,  0.8822],\n",
       "         [-0.2155,  1.4676,  0.3733,  1.6645, -2.1963]],\n",
       "\n",
       "        [[ 0.3817, -1.3816, -0.0126,  1.1476,  1.8669],\n",
       "         [ 0.5688,  0.9381, -1.3945,  0.6863, -1.5389],\n",
       "         [-0.2369,  0.7993, -1.0803, -0.4629, -0.2810]],\n",
       "\n",
       "        [[ 0.7018,  1.2853, -0.2395,  1.8107,  0.1803],\n",
       "         [-1.4307, -0.3072,  0.6677,  0.5036, -1.2250],\n",
       "         [ 0.6976,  0.3290, -2.0245, -0.5033, -0.4459]],\n",
       "\n",
       "        [[ 0.1244, -0.1468,  0.2397,  0.2596, -0.5887],\n",
       "         [ 1.0288,  1.4734, -1.6026,  0.9561, -0.8791],\n",
       "         [ 0.0268,  0.7016,  0.7880,  0.0460, -2.4271]],\n",
       "\n",
       "        [[-2.4209,  0.3694,  1.0487,  0.8913,  0.6070],\n",
       "         [ 1.2738, -0.4474,  0.0166, -0.1589,  0.2163],\n",
       "         [-1.1257,  0.6097,  0.2396, -1.6827,  0.5633]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a210d",
   "metadata": {},
   "source": [
    "We can now create a transformer easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6241e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTensorDict(nn.Module):\n",
    "    def __init__(self, num_blocks, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.ModuleList([TransformerBlockTensorDict(to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads) for _ in range(num_blocks)])\n",
    "    def forward(self, X_tensor_dict):\n",
    "        for transformer_block in self.transformer:\n",
    "            transformer_block(X_tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "544f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704bddb",
   "metadata": {},
   "source": [
    "For an encoder, we just need to take the same tokens for both queries, keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52dbf4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3641, -0.0979, -0.0854, -0.4905, -2.0029],\n",
       "         [-1.5806,  0.5326,  0.6632,  0.7920, -1.1313],\n",
       "         [ 0.5733, -0.1321,  2.1497,  0.6715, -0.2256]],\n",
       "\n",
       "        [[-0.5301,  1.3014,  0.8339, -1.6371, -0.0447],\n",
       "         [-0.1658,  0.9115, -0.1586, -0.1376, -1.6049],\n",
       "         [-0.1376,  0.6356,  1.5934,  0.7616, -1.6211]],\n",
       "\n",
       "        [[-0.7808,  0.1323,  0.3524, -1.8699, -1.2661],\n",
       "         [-0.3532,  0.0802,  1.8762, -0.0252, -1.0859],\n",
       "         [ 0.4886,  1.1930,  1.5847,  0.0510, -0.3773]],\n",
       "\n",
       "        [[-0.5639,  0.4097,  1.2614, -1.1658,  0.8153],\n",
       "         [ 0.9616, -1.0353,  0.8457,  0.3561, -1.7874],\n",
       "         [-0.3008, -0.3083,  1.2756,  0.7932, -1.5570]],\n",
       "\n",
       "        [[ 1.6996,  0.6104,  0.7166, -1.4791, -0.0746],\n",
       "         [-1.3742, -0.0917,  0.3204,  0.4544, -1.6289],\n",
       "         [ 0.7167,  0.8835,  1.0875, -0.8911, -0.9494]],\n",
       "\n",
       "        [[-0.3857,  1.2185,  0.8044, -1.2474, -0.6684],\n",
       "         [-2.6451,  0.3813,  0.8183,  0.2206, -0.0257],\n",
       "         [-0.2125,  0.9058,  1.3390, -0.0635, -0.4396]],\n",
       "\n",
       "        [[ 0.4440, -0.4641,  1.3416,  0.4208,  0.0535],\n",
       "         [-0.0167,  0.5248,  0.4601,  1.1979, -2.6929],\n",
       "         [-0.1802,  0.8493,  0.2579, -1.4159, -0.7799]],\n",
       "\n",
       "        [[ 0.0957,  0.2631,  1.9058, -0.7983, -2.1256],\n",
       "         [-0.8988, -0.3532,  1.4373,  0.5188, -0.8031],\n",
       "         [ 0.4242, -0.5689,  0.5862,  0.9721, -0.6552]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder = TransformerTensorDict(6, \"X_to\", \"X_to\", to_dim, to_len, to_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_encoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379ac76",
   "metadata": {},
   "source": [
    "For a decoder, we now can extract info from X_from into X_to. X_to will map to queries whereas X_from will map to keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "913b3979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4194,  1.1577, -0.2249, -0.2299, -1.6838],\n",
       "         [-0.4603,  1.5326,  0.1736,  0.4194, -2.1895],\n",
       "         [ 0.2842,  0.8026,  1.1243, -0.1371, -0.9882]],\n",
       "\n",
       "        [[-0.3067,  1.4502,  0.5999, -1.0000, -0.6322],\n",
       "         [-0.2193,  2.2219, -0.2861, -0.1852, -1.1817],\n",
       "         [ 0.0121,  0.7552,  0.8953, -0.3838, -1.7396]],\n",
       "\n",
       "        [[-0.2220,  0.9376,  0.4108, -0.8514, -1.4368],\n",
       "         [-0.2243,  1.0650,  1.1564, -0.5117, -1.8274],\n",
       "         [ 0.3239,  1.7627,  0.7365, -0.2319, -1.0873]],\n",
       "\n",
       "        [[ 0.0923,  0.1925,  2.0104, -1.0669,  0.2943],\n",
       "         [ 1.0389, -0.3586,  0.0279, -0.2836, -1.3698],\n",
       "         [-0.2385,  0.1469,  1.1481,  0.5598, -2.1937]],\n",
       "\n",
       "        [[ 1.3624,  0.0818,  0.6500, -1.9682, -0.3359],\n",
       "         [-0.3614,  0.9265,  0.2931,  0.2009, -1.4732],\n",
       "         [ 0.2946,  1.1101,  1.3561, -1.0921, -1.0449]],\n",
       "\n",
       "        [[ 0.1569,  1.4944,  0.1292, -1.0900, -0.8406],\n",
       "         [-1.6930,  0.3846,  0.9151,  0.1136, -1.2707],\n",
       "         [ 0.4416,  1.6022,  1.1814, -0.6376, -0.8870]],\n",
       "\n",
       "        [[ 0.6334, -0.2367,  1.1179, -0.5009, -0.3828],\n",
       "         [ 0.0639,  1.2607,  0.4867,  0.1112, -2.5056],\n",
       "         [ 0.6137,  1.0620,  0.6164, -1.4468, -0.8929]],\n",
       "\n",
       "        [[-0.1152,  1.1531,  1.4088, -0.6771, -2.7837],\n",
       "         [-0.1132,  0.3721,  1.0719,  0.0737, -1.1365],\n",
       "         [ 0.3906,  0.4455,  0.2721,  0.2531, -0.6153]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder = TransformerTensorDict(6, \"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_decoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3698ba",
   "metadata": {},
   "source": [
    "Now we can look at both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9c19fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fb30839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
