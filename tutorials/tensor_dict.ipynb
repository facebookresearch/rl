{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61f510e",
   "metadata": {},
   "source": [
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c0ad4",
   "metadata": {},
   "source": [
    "TensorDict is a new tensor structure introduced in torchrl. With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. TensorDict aims at making it more convenient to deal with multiple tensors at the same time. Furthermore, different RL algorithms can deal with different input and outputs. The TensorDict allows to abstract away the differences between these algorithmes\n",
    "\n",
    "### Example\n",
    "As a concrete example, let us take DQN and PPO. The first uses a deterministic policy that applies an argmax operator to a collection of values associated with each action for a given observation.  The second has a parametric policy that outputs a distribution over the space of the available actions. Here are the pseudos codes:\n",
    "\n",
    "<code>\n",
    "# DQN\n",
    "data = []\n",
    "for i in range(max_steps):\n",
    "    action, values = value_network(observation)  # action = values.argmax(-1)\n",
    "    observation, reward, done, *other = env.step(action)\n",
    "    data.append((action, values, observation, reward, done))\n",
    "</code>\n",
    "<code>\n",
    "# PPO\n",
    "data = []\n",
    "for i in range(max_steps):\n",
    "    action, action_log_prob = policy(observation)\n",
    "    observation, reward, done, *other = env.step(action)\n",
    "    data.append((action, action_log_prob, observation, reward, done))\n",
    "\n",
    "</code>\n",
    "\n",
    "Ideally we would like to abstract this away into the same code:\n",
    "\n",
    "<code>\n",
    "collections = []\n",
    "for i in range(max_steps):\n",
    "    collection_of_values = policy(collection_of_values)\n",
    "    collection_of_values = env_step(collection_of_values)\n",
    "    collections.append(collection_of_values)\n",
    "</code>\n",
    "The differences in the algorithms will now lie in the `policy`, the `env_step` and the initial `collection_of_values` but the main algorithm is now the same for both algorithm. This abstraction allows for more modular and reusable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac324978",
   "metadata": {},
   "source": [
    "## Tensor Dict Python Dictionary behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4b705",
   "metadata": {},
   "source": [
    "TensorDict shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791a3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46c8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc767a",
   "metadata": {},
   "source": [
    "If we want to access a certain key, it is explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16360ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[\"a\"])\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e1ee6",
   "metadata": {},
   "source": [
    "#### TensorDict.keys()\n",
    "We can access the dict keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6212e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for key in tensordict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c4fe4c",
   "metadata": {},
   "source": [
    "#### TensorDict.values()\n",
    "We can also retrieve the values of the dict. On the contrary of python dicts, we return a generator and not a list for memory efficiency reasons. Indeed, python dictionnary are not designed to store tensors in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4538e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _TensorDict.values at 0x10e85f3c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3030acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc512bc",
   "metadata": {},
   "source": [
    "#### TensorDict.update()\n",
    "We can also use the update function like for dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884c3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "c is set as tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\":torch.ones((3, 4, 5))})\n",
    "tensordict.update({\"c\":torch.ones((3, 4, 2))})\n",
    "print(f\"a is now {tensordict['a']}\")\n",
    "print(f\"c is set as {tensordict['c']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbadaafb",
   "metadata": {},
   "source": [
    "#### TensorDict del key\n",
    "Tensor Dict also support keys deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b5920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b'])\n"
     ]
    }
   ],
   "source": [
    "del tensordict[\"c\"]\n",
    "print(tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b6665",
   "metadata": {},
   "source": [
    "## TensorDict as a pytorch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f292ab8",
   "metadata": {},
   "source": [
    "But wait? Can't we do this with a classical dict? \n",
    "Well, we would like the TensorDict to keep some nice Pytorch properties. TensorDict combines the advantages of the Python dictionary and of a Pytorch Tensor.\n",
    "TensorDict has a batch size. It is not inferred automatically by looking at the tensors, but must be set when creating the TensorDict\n",
    "\n",
    "TensorDict is a tensor container where all tensors are stored in akey-value pair fashion and where each element shares at least the following features:\n",
    "- device;\n",
    "- memory location (shared, memory-mapped array, ...);\n",
    "- batch size (i.e. n^th first dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3da095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.tensordict.tensordict import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fd8b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)\n",
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c47805",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c926a9",
   "metadata": {},
   "source": [
    "Tensor dict has a batch size which is shared across all tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc68f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc180b",
   "metadata": {},
   "source": [
    "You cannot have items that don't share the batch size inside the TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41737242",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensordict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:356\u001b[0m, in \u001b[0;36m_TensorDict.update\u001b[0;34m(self, input_dict_or_td, clone, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clone:\n\u001b[1;32m    355\u001b[0m         value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:1646\u001b[0m, in \u001b[0;36mTensorDict.set\u001b[0;34m(self, key, value, inplace, _run_checks, _meta_val)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict \u001b[38;5;129;01mand\u001b[39;00m inplace:\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_(key, value)\n\u001b[0;32m-> 1646\u001b[0m proc_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tensor_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_shared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# check_tensor_shape=_run_checks\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict[key] \u001b[38;5;241m=\u001b[39m proc_value\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict_meta[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1654\u001b[0m     MetaTensor(\n\u001b[1;32m   1655\u001b[0m         proc_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _meta_val\n\u001b[1;32m   1661\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:480\u001b[0m, in \u001b[0;36m_TensorDict._process_tensor\u001b[0;34m(self, input, check_device, check_tensor_shape, check_shared)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_shared is not authorized anymore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_tensor_shape \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch dimension mismatch, got self.batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and tensor.shape[:self.batch_dims]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# minimum ndimension is 1\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"c\":torch.zeros(4,3,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a02a32",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a624475",
   "metadata": {},
   "source": [
    "#### Cloning\n",
    "TensorDict supports cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f579c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "tensordict_clone[\"a\"] = torch.ones(*tensordict.shape,5)\n",
    "print(tensordict[\"a\"])\n",
    "print(tensordict_clone[\"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71075821",
   "metadata": {},
   "source": [
    "#### Slicing and indexing\n",
    "Slicing and indexing is supported among the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710d8b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef348fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8230353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb47f65",
   "metadata": {},
   "source": [
    "TensorDict support other tensor operations such as torch.cat, reshape, undind(dim), view(\\*shape), squeeze(dim), unsqueeze(dim), permute(\\*dims) requiring the operations to comply with the batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3b3002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d74f22",
   "metadata": {},
   "source": [
    "#### Casting to device\n",
    "TensorDict supports casting to devices with the .to(device) function as with regular tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053ef9f",
   "metadata": {},
   "source": [
    "## How to use them in practice? The tensor the TensorDictModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94af8a2",
   "metadata": {},
   "source": [
    "Now that we have seen the TensorDict object, how do we use it in pratice? We introduce the TensorDictModule. The TensorDictModule is an nn.Module that takes a TensorDict in his forward method. The user defines the keys that the module will take as an input and write the output in the same TensorDict at a given set of key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4439dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import TensorDictModule\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f76450",
   "metadata": {},
   "source": [
    "### Example: Simple Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614d32f",
   "metadata": {},
   "source": [
    "Let's imagine we have 2 entries Tensor dict, a and b and we only want to affect a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1acaf3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        a_out: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3,10),in_keys=[\"a\"], out_keys=[\"a_out\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a879d0",
   "metadata": {},
   "source": [
    "We can also do it inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f22bdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3,10),in_keys=[\"a\"], out_keys=[\"a\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2866e",
   "metadata": {},
   "source": [
    "### Example: 2 input merging with 2 linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166868f",
   "metadata": {},
   "source": [
    "Now lets imagine a more complex network that takes 2 entries and average them into a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5ba235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeLinear(nn.Module):\n",
    "    def __init__(self, in_1, in_2, out):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out)\n",
    "        self.linear_2  = nn.Linear(in_2,out)\n",
    "    def forward(self, x_1, x_2):\n",
    "        return (self.linear_1(x_1) + self.linear_2(x_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021c97e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        c: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3), \"c\":torch.randn(5,4)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MergeLinear(3, 4, 10),in_keys=[\"a\",\"c\"], out_keys=[\"output\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd579195",
   "metadata": {},
   "source": [
    "### Example: 1 input to 2 outputs linear layer\n",
    "We can also map to multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "632426fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLinear(nn.Module):\n",
    "    def __init__(self, in_1, out_1, out_2):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out_1)\n",
    "        self.linear_2  = nn.Linear(in_1,out_2)\n",
    "    def forward(self, x):\n",
    "        return self.linear_1(x), self.linear_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435ae253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        output_1: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output_2: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MultiHeadLinear(3, 4, 10),in_keys=[\"a\"], out_keys=[\"output_1\", \"output_2\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7594721",
   "metadata": {},
   "source": [
    "As we shown previously, the TensorDictModule can take any nn.Module and perform the operations inside a TensorDict. When having multiple input keys and output keys, make sure they match the order in the module.\n",
    "The tensordictmodule allows to use only the tensors that we want and keep the output inside the same object. It can even perform the operations inplace by setting the output key to be the same as an already set key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a2ed0",
   "metadata": {},
   "source": [
    "### Example: A transformer with TensorDict?\n",
    "Let's attempt to create a transformer with TensorDict and TensorDictModule\n",
    "\n",
    "Disclaimer: This implementation isn't to be \"better\" than a tensor based implementation. It is just meant to showcase the TensorDictModule features.\n",
    "\n",
    "Let's first implement the classical transformers blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5e05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokensToQKV(nn.Module):\n",
    "    def __init__(self, to_dim, from_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(to_dim, latent_dim)\n",
    "        self.k = nn.Linear(from_dim, latent_dim)\n",
    "        self.v = nn.Linear(from_dim, latent_dim)\n",
    "    def forward(self, X_to, X_from):\n",
    "        Q = self.q(X_to)\n",
    "        K = self.k(X_from)\n",
    "        V = self.v(X_from)\n",
    "        return Q, K, V\n",
    "\n",
    "class SplitHeads(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, to_num, latent_dim = Q.shape\n",
    "        _, from_num, _ = K.shape\n",
    "        d_tensor = latent_dim // self.num_heads\n",
    "        Q = Q.reshape(batch_size, to_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        K = K.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        V = V.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        return Q, K, V\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, latent_dim, to_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(latent_dim, to_dim)\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, n_heads, to_num, d_in = Q.shape\n",
    "        attn = self.softmax(Q @ K.transpose(2,3) / d_in)\n",
    "        out = attn @ V\n",
    "        out = self.out(out.transpose(1, 2).reshape(batch_size, to_num, n_heads*d_in))\n",
    "        return out, attn\n",
    "class SkipLayerNorm(nn.Module):\n",
    "    def __init__(self, to_len, to_dim):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((to_len, to_dim))\n",
    "    def forward(self, x_0, x_1):\n",
    "        return self.layer_norm(x_0+x_1)\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, to_dim, hidden_dim, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(to_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, to_dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.FFN(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c49b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockTensorDict(nn.Module):\n",
    "    def __init__(self, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer_block = nn.Sequential(\n",
    "            TensorDictModule(TokensToQKV(to_dim, from_dim, latent_dim), in_keys=[to_name, from_name], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(SplitHeads(num_heads), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(Attention(latent_dim, to_dim), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"X_out\",\"Attn\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "            TensorDictModule(FFN(to_dim, 4*to_dim), in_keys=[\"X_to\"], out_keys=[\"X_out\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "        )\n",
    "    def forward(self, X_tensor_dict):\n",
    "        self.transformer_block(X_tensor_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fa8d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        Attn: Tensor(torch.Size([8, 2, 3, 10]), dtype=torch.float32),\n",
       "        K: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        Q: Tensor(torch.Size([8, 2, 3, 5]), dtype=torch.float32),\n",
       "        V: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        X_from: Tensor(torch.Size([8, 10, 6]), dtype=torch.float32),\n",
       "        X_out: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32),\n",
       "        X_to: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "transformer_block = TransformerBlockTensorDict(\"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_block(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a53298",
   "metadata": {},
   "source": [
    "The output of the transformer layer can now be found at tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12c66c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2140e-01,  9.3885e-02,  1.5475e+00, -8.5764e-01, -1.0164e+00],\n",
       "         [ 6.1844e-01,  4.2928e-01,  1.2559e+00, -1.7318e-02, -1.0785e+00],\n",
       "         [ 3.6746e-01, -2.0010e+00,  5.7185e-01,  1.3700e+00, -1.0621e+00]],\n",
       "\n",
       "        [[ 1.8018e+00,  1.7676e-01,  1.3061e+00,  5.5536e-04,  9.5903e-01],\n",
       "         [-1.7914e-02, -1.1058e+00, -1.0330e+00, -5.6826e-01,  6.1741e-01],\n",
       "         [ 1.0086e+00, -2.1221e+00,  5.2469e-02, -5.4785e-01, -5.2776e-01]],\n",
       "\n",
       "        [[-5.7215e-03, -2.1323e+00, -6.8256e-01, -5.2980e-02,  2.1093e+00],\n",
       "         [-3.1369e-01, -1.0205e+00,  1.2342e+00, -4.3158e-01,  1.8713e-01],\n",
       "         [ 1.2250e+00, -3.5429e-01,  3.3673e-01, -7.2250e-01,  6.2381e-01]],\n",
       "\n",
       "        [[ 1.1720e+00, -1.2023e+00, -4.1971e-01, -3.9235e-01, -5.0843e-01],\n",
       "         [ 1.4071e+00, -7.0667e-01, -9.0403e-01,  9.7855e-01,  1.9402e+00],\n",
       "         [ 5.9586e-01, -2.0236e-01, -5.3443e-01, -1.6470e+00,  4.2355e-01]],\n",
       "\n",
       "        [[ 2.2837e-01, -2.2963e-02,  2.4110e-01, -9.2972e-01,  5.7418e-01],\n",
       "         [ 1.1679e+00, -7.8923e-01, -1.7175e-01,  3.6727e-01,  1.1527e+00],\n",
       "         [ 1.8616e+00, -3.0584e-01, -2.1084e+00, -1.4724e+00,  2.0712e-01]],\n",
       "\n",
       "        [[-2.6172e-01, -2.2121e+00, -7.4566e-01,  1.2002e+00, -7.5803e-01],\n",
       "         [ 5.2748e-01,  3.9661e-01,  1.6845e+00,  9.5950e-01, -3.9241e-01],\n",
       "         [-7.8969e-01, -5.8632e-01,  6.8664e-01, -7.5952e-01,  1.0505e+00]],\n",
       "\n",
       "        [[ 1.8870e+00, -3.2287e-01, -9.8743e-03, -8.0076e-01, -9.8274e-01],\n",
       "         [-9.8188e-02,  1.4190e+00, -2.8326e-01,  8.4426e-01, -5.9501e-01],\n",
       "         [-2.5563e-01, -2.1496e+00, -3.9752e-01,  5.6409e-01,  1.1811e+00]],\n",
       "\n",
       "        [[ 4.9171e-01, -8.9689e-01,  8.8269e-01,  1.7786e+00, -6.3821e-02],\n",
       "         [-3.8188e-01, -1.4144e+00, -7.0545e-01, -1.0574e+00,  1.4502e+00],\n",
       "         [ 2.6302e-01, -1.0660e+00,  4.6133e-01, -1.0306e+00,  1.2888e+00]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd3c7b",
   "metadata": {},
   "source": [
    "We can now create a transformer easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19e0659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTensorDict(nn.Module):\n",
    "    def __init__(self, num_blocks, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.ModuleList([TransformerBlockTensorDict(to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads) for _ in range(num_blocks)])\n",
    "    def forward(self, X_tensor_dict):\n",
    "        for transformer_block in self.transformer:\n",
    "            transformer_block(X_tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd865d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86885fbc",
   "metadata": {},
   "source": [
    "For an encoder, we can do it easily as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c9d6d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5433, -2.1209,  0.6917,  0.1949, -0.2383],\n",
       "         [-0.2084,  1.1901,  0.1548, -1.2804,  0.3292],\n",
       "         [ 1.8350, -1.2308,  0.2563, -0.9090,  0.7924]],\n",
       "\n",
       "        [[ 0.7642, -0.8773,  0.6102, -1.9610, -0.2547],\n",
       "         [ 0.8582, -0.8673,  1.6634, -0.5311, -1.3557],\n",
       "         [ 0.5985, -0.6759,  0.8806, -0.0338,  1.1816]],\n",
       "\n",
       "        [[ 0.1173, -1.0630, -1.1206, -0.9292,  0.6910],\n",
       "         [-0.5904,  0.2967,  1.0146, -0.1985, -0.1382],\n",
       "         [ 2.3575, -0.4132,  1.5436, -1.2285, -0.3390]],\n",
       "\n",
       "        [[-0.0839,  0.3025,  1.2402, -1.1337, -0.3312],\n",
       "         [ 0.1848, -0.5644, -0.9238, -1.2078,  0.7454],\n",
       "         [ 0.9539, -0.4605,  2.5865, -0.8541, -0.4540]],\n",
       "\n",
       "        [[ 2.2012,  0.3198, -0.1624, -1.0218, -0.2963],\n",
       "         [-1.1105,  0.0330, -0.6841,  0.2308,  0.1053],\n",
       "         [ 2.2178, -1.1405,  0.0187, -0.9278,  0.2166]],\n",
       "\n",
       "        [[ 0.1762,  0.1206, -0.9111, -0.8480,  0.8383],\n",
       "         [-0.0356,  1.9972,  1.2416, -1.9975,  0.2798],\n",
       "         [-1.5899,  0.6967,  0.2188, -0.2017,  0.0147]],\n",
       "\n",
       "        [[ 0.5766, -1.0382, -0.3026, -0.9678,  0.1475],\n",
       "         [-0.2206,  0.6656, -0.0131, -0.7690, -0.2181],\n",
       "         [ 1.7309, -0.6701,  2.5907, -0.5225, -0.9894]],\n",
       "\n",
       "        [[ 0.8108, -0.8168,  0.2928, -0.8560,  0.6063],\n",
       "         [ 1.3993, -1.0990,  2.3342, -0.6302, -0.6805],\n",
       "         [-0.3689, -1.0603,  1.0844, -0.3315, -0.6845]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder = TransformerTensorDict(6, \"X_to\", \"X_to\", to_dim, to_len, to_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_encoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994eaa5",
   "metadata": {},
   "source": [
    "For a decoder we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c3783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9111, -0.9565,  0.8885, -0.1153, -1.1195],\n",
       "         [-1.0822,  1.9428, -0.1168, -1.2518, -0.4014],\n",
       "         [ 1.6768, -1.1258,  0.4677, -0.1539,  0.4362]],\n",
       "\n",
       "        [[ 0.2126, -0.9831,  0.8968, -1.4953, -1.0055],\n",
       "         [ 0.8913,  0.0649,  0.6585, -0.7806, -2.0843],\n",
       "         [ 1.5738,  0.4048,  0.6604,  0.7997,  0.1859]],\n",
       "\n",
       "        [[-0.1787, -0.4171, -1.1724, -0.7935,  0.4380],\n",
       "         [-0.3860,  1.7195,  0.8667, -1.2160, -0.2223],\n",
       "         [ 1.6916,  0.1081,  1.4817, -1.3484, -0.5712]],\n",
       "\n",
       "        [[ 0.3393,  0.4130,  0.7333, -1.0726, -0.8733],\n",
       "         [ 0.9412, -0.4980, -0.0214, -0.0619,  0.4108],\n",
       "         [ 1.5666, -0.0143,  1.5400, -1.2883, -2.1144]],\n",
       "\n",
       "        [[ 2.3167,  0.4312, -0.4086,  0.1072, -1.3709],\n",
       "         [-0.6496,  0.0503, -0.5773,  0.4249, -0.6153],\n",
       "         [ 2.2431, -0.4351, -0.3872, -0.3861, -0.7434]],\n",
       "\n",
       "        [[ 0.7115,  0.0280, -0.2837, -0.1418,  0.2284],\n",
       "         [-0.3786,  1.7935,  1.5064, -1.9357, -0.8157],\n",
       "         [-0.8887,  1.5851, -0.0724, -0.4470, -0.8894]],\n",
       "\n",
       "        [[ 0.7716, -0.7878,  0.1092, -0.8322,  0.1236],\n",
       "         [-0.2652,  0.5158,  0.1450, -1.0936, -0.9748],\n",
       "         [ 1.3011, -0.0770,  2.7170, -0.5874, -1.0653]],\n",
       "\n",
       "        [[ 0.7893, -0.3034,  0.4487, -0.8292,  0.2726],\n",
       "         [ 1.0496, -0.7812,  1.6862, -0.5165, -1.8188],\n",
       "         [ 0.6703, -0.0561,  1.4446, -0.5093, -1.5469]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder = TransformerTensorDict(6, \"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_decoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "346ebe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e309c6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7ecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
