{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed498bdd",
   "metadata": {},
   "source": [
    "# TensorDict tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a938a2",
   "metadata": {},
   "source": [
    "TensorDict is a new tensor structure introduced in torchrl. With RL, you need to be able to deal with multiple tensors such as actions, observations and reward. TensorDict aims at making it more convenient to deal with multiple tensors at the same time. Furthermore, different RL algorithms can deal with different input and outputs. The TensorDict allows to abstract away the differences between these algorithmes\n",
    "\n",
    "### Motivation\n",
    "As a concrete example, let us take DQN and PPO. The first uses a deterministic policy that applies an argmax operator to a collection of values associated with each action for a given observation.  The second has a parametric policy that outputs a distribution over the space of the available actions. Here are the pseudos codes:\n",
    "\n",
    "<code>\n",
    "# DQN\n",
    "data = []\n",
    "for i in range(max_steps):\n",
    "    action, values = value_network(observation)  # action = values.argmax(-1)\n",
    "    observation, reward, done, *other = env.step(action)\n",
    "    data.append((action, values, observation, reward, done))\n",
    "</code>\n",
    "<code>\n",
    "# PPO\n",
    "data = []\n",
    "for i in range(max_steps):\n",
    "    action, action_log_prob = policy(observation)\n",
    "    observation, reward, done, *other = env.step(action)\n",
    "    data.append((action, action_log_prob, observation, reward, done))\n",
    "\n",
    "</code>\n",
    "\n",
    "Ideally we would like to abstract this away into the same code:\n",
    "\n",
    "<code>\n",
    "collections = []\n",
    "for i in range(max_steps):\n",
    "    collection_of_values = policy(collection_of_values)\n",
    "    collection_of_values = env_step(collection_of_values)\n",
    "    collections.append(collection_of_values)\n",
    "</code>\n",
    "The differences in the algorithms will now lie in the `policy`, the `env_step` and the initial `collection_of_values` but the main algorithm is now the same for both algorithm. This abstraction allows for more modular and reusable code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e44de1",
   "metadata": {},
   "source": [
    "## Tensor Dict Python Dictionary behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b27f7f",
   "metadata": {},
   "source": [
    "TensorDict shares a lot of features with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff626668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1985ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66356d",
   "metadata": {},
   "source": [
    "If we want to access a certain key, it is explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d4689c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[\"a\"])\n",
    "print(tensordict[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c4d65",
   "metadata": {},
   "source": [
    "Also works with get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7212a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(tensordict.get(\"a\"))\n",
    "print(tensordict.get(\"a\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c82ca1",
   "metadata": {},
   "source": [
    "#### TensorDict.keys()\n",
    "Keys can be retrieved to TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef88aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for key in tensordict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43066ab2",
   "metadata": {},
   "source": [
    "#### TensorDict.values()\n",
    "The values of a TensorDict can be retrieved with the values() function. On the contrary of python dicts, the values() function return a generator and not a list for memory efficiency reasons. Indeed, python dictionnary are not designed to store tensors which can take a lot of space in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa0d99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _TensorDict.values at 0x11711d580>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270dc4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for value in tensordict.values():\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17079498",
   "metadata": {},
   "source": [
    "#### TensorDict.set()\n",
    "The set function can be used to set new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c088852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c is set as tensor([[[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]],\n",
      "\n",
      "         [[0., 0.],\n",
      "          [0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict.set(\"c\", torch.zeros((3, 4, 2, 2)))\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"c is set as {tensordict['c']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8783e1",
   "metadata": {},
   "source": [
    "#### TensorDict.update()\n",
    "The update function can be used to update the dict with other dict values (Or TensorDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7061f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is now tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "d is set as tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"a\":torch.ones((3, 4, 5)), \"d\":torch.ones((3, 4, 2))})\n",
    "# Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)), \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n",
    "print(f\"a is now {tensordict['a']}\")\n",
    "print(f\"d is set as {tensordict['d']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7434c1",
   "metadata": {},
   "source": [
    "#### TensorDict del key\n",
    "TensorDict also support keys deletion with the del operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83a86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'b', 'd'])\n"
     ]
    }
   ],
   "source": [
    "del tensordict[\"c\"]\n",
    "print(tensordict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada11e0",
   "metadata": {},
   "source": [
    "## TensorDict as a pytorch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af83e0f",
   "metadata": {},
   "source": [
    "But wait? Can't we do this with a classical dict? \n",
    "Well, we would like the TensorDict to keep some nice Pytorch properties. TensorDict combines the advantages of the Python dictionary and of a Pytorch Tensor.\n",
    "TensorDict has a batch size. It is not inferred automatically by looking at the tensors, but must be set when creating the TensorDict.\n",
    "\n",
    "TensorDict is a tensor container where all tensors are stored in akey-value pair fashion and where each element shares at least the following features:\n",
    "- device;\n",
    "- memory location (shared, memory-mapped array, ...);\n",
    "- batch size (i.e. n^th first dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345e0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.tensordict.tensordict import TensorDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1b27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),\n",
      "        b: Tensor(torch.Size([3, 4, 1]), dtype=torch.float32)},\n",
      "    batch_size=torch.Size([3, 4]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\": torch.zeros(3, 4, 5), \"b\": torch.zeros(3, 4)}, batch_size=[3, 4])\n",
    "print(tensordict)\n",
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc15741",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd455eaa",
   "metadata": {},
   "source": [
    "Tensor dict has a batch size which is shared across all tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e060c706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Tensor dict is of size torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our Tensor dict is of size {tensordict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4a862",
   "metadata": {},
   "source": [
    "You cannot have items that don't share the batch size inside the same TensorDict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d00f2b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensordict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:356\u001b[0m, in \u001b[0;36m_TensorDict.update\u001b[0;34m(self, input_dict_or_td, clone, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clone:\n\u001b[1;32m    355\u001b[0m         value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:1646\u001b[0m, in \u001b[0;36mTensorDict.set\u001b[0;34m(self, key, value, inplace, _run_checks, _meta_val)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict \u001b[38;5;129;01mand\u001b[39;00m inplace:\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_(key, value)\n\u001b[0;32m-> 1646\u001b[0m proc_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tensor_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_shared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# check_tensor_shape=_run_checks\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict[key] \u001b[38;5;241m=\u001b[39m proc_value\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensordict_meta[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1654\u001b[0m     MetaTensor(\n\u001b[1;32m   1655\u001b[0m         proc_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _meta_val\n\u001b[1;32m   1661\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/pytorch/rl/torchrl/data/tensordict/tensordict.py:480\u001b[0m, in \u001b[0;36m_TensorDict._process_tensor\u001b[0;34m(self, input, check_device, check_tensor_shape, check_shared)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_shared is not authorized anymore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_tensor_shape \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch dimension mismatch, got self.batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and tensor.shape[:self.batch_dims]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dims]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# minimum ndimension is 1\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: batch dimension mismatch, got self.batch_size=torch.Size([3, 4]) and tensor.shape[:self.batch_dims]=torch.Size([4, 3])"
     ]
    }
   ],
   "source": [
    "tensordict.update({\"c\":torch.zeros(4,3,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5d799",
   "metadata": {},
   "source": [
    "#### Cloning\n",
    "TensorDict supports cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1ab1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tensordict_clone = tensordict.clone()\n",
    "tensordict_clone[\"a\"] = torch.ones(*tensordict.shape,5)\n",
    "print(tensordict[\"a\"])\n",
    "print(tensordict_clone[\"a\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857823f7",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform tensor operations among the batch dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff6353",
   "metadata": {},
   "source": [
    "#### Slicing and indexing\n",
    "Slicing and indexing is supported among the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e170a64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a12a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([2, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([2, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89ff33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([3, 2, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([3, 2, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6007915",
   "metadata": {},
   "source": [
    "TensorDict support other tensor operations such as torch.cat, reshape, undind(dim), view(\\*shape), squeeze(dim), unsqueeze(dim), permute(\\*dims) requiring the operations to comply with the batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49ae45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([12, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([12, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape\n",
    "tensordict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491a987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([6, 4, 5]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([6, 4, 1]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([6, 4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cat\n",
    "torch.cat([tensordict, tensordict.clone()], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293442",
   "metadata": {},
   "source": [
    "#### Casting to device\n",
    "TensorDict supports casting to devices with the .to(device) function as with regular tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548af86",
   "metadata": {},
   "source": [
    "## How to use them in practice? The tensor the TensorDictModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef1786",
   "metadata": {},
   "source": [
    "Now that we have seen the TensorDict object, how do we use it in pratice? We introduce the TensorDictModule. The TensorDictModule is an nn.Module that takes a TensorDict in his forward method. The user defines the keys that the module will take as an input and write the output in the same TensorDict at a given set of key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c59b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules import TensorDictModule\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab1825",
   "metadata": {},
   "source": [
    "### Example: Simple Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd4be6",
   "metadata": {},
   "source": [
    "Let's imagine we have 2 entries Tensor dict, a and b and we only want to affect a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "120540b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        a_out: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3,10),in_keys=[\"a\"], out_keys=[\"a_out\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590ddfb",
   "metadata": {},
   "source": [
    "We can also do it inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d28e94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 10]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "linear = TensorDictModule(nn.Linear(3,10),in_keys=[\"a\"], out_keys=[\"a\"])\n",
    "linear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6fec6",
   "metadata": {},
   "source": [
    "### Example: 2 input merging with 2 linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bf86b",
   "metadata": {},
   "source": [
    "Now lets imagine a more complex network that takes 2 entries and average them into a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5871748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeLinear(nn.Module):\n",
    "    def __init__(self, in_1, in_2, out):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out)\n",
    "        self.linear_2  = nn.Linear(in_2,out)\n",
    "    def forward(self, x_1, x_2):\n",
    "        return (self.linear_1(x_1) + self.linear_2(x_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a615ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        c: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3), \"c\":torch.randn(5,4)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MergeLinear(3, 4, 10),in_keys=[\"a\",\"c\"], out_keys=[\"output\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eea40a",
   "metadata": {},
   "source": [
    "### Example: 1 input to 2 outputs linear layer\n",
    "We can also map to multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d969a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLinear(nn.Module):\n",
    "    def __init__(self, in_1, out_1, out_2):\n",
    "        super().__init__()\n",
    "        self.linear_1  = nn.Linear(in_1,out_1)\n",
    "        self.linear_2  = nn.Linear(in_1,out_2)\n",
    "    def forward(self, x):\n",
    "        return self.linear_1(x), self.linear_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04bd7977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(torch.Size([5, 3]), dtype=torch.float32),\n",
       "        b: Tensor(torch.Size([5, 4, 3]), dtype=torch.float32),\n",
       "        output_1: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n",
       "        output_2: Tensor(torch.Size([5, 10]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = TensorDict({\"a\":torch.randn(5,3), \"b\":torch.randn(5,4,3)}, batch_size=[5])\n",
    "mergelinear = TensorDictModule(MultiHeadLinear(3, 4, 10),in_keys=[\"a\"], out_keys=[\"output_1\", \"output_2\"])\n",
    "mergelinear(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d6658",
   "metadata": {},
   "source": [
    "As we shown previously, the TensorDictModule can take any nn.Module and perform the operations inside a TensorDict. When having multiple input keys and output keys, make sure they match the order in the module.\n",
    "The tensordictmodule allows to use only the tensors that we want and keep the output inside the same object. It can even perform the operations inplace by setting the output key to be the same as an already set key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d946d8",
   "metadata": {},
   "source": [
    "### Example: A transformer with TensorDict?\n",
    "Let's attempt to create a transformer with TensorDict and TensorDictModule\n",
    "\n",
    "Disclaimer: This implementation don't claim to be \"better\" than a classical tensor-based implementation. It is just meant to showcase the TensorDictModule features.\n",
    "For simplicity we will not have positional encoders.\n",
    "\n",
    "Let's first implement the classical transformers blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f21f79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokensToQKV(nn.Module):\n",
    "    def __init__(self, to_dim, from_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(to_dim, latent_dim)\n",
    "        self.k = nn.Linear(from_dim, latent_dim)\n",
    "        self.v = nn.Linear(from_dim, latent_dim)\n",
    "    def forward(self, X_to, X_from):\n",
    "        Q = self.q(X_to)\n",
    "        K = self.k(X_from)\n",
    "        V = self.v(X_from)\n",
    "        return Q, K, V\n",
    "\n",
    "class SplitHeads(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, to_num, latent_dim = Q.shape\n",
    "        _, from_num, _ = K.shape\n",
    "        d_tensor = latent_dim // self.num_heads\n",
    "        Q = Q.reshape(batch_size, to_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        K = K.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        V = V.reshape(batch_size, from_num, self.num_heads, d_tensor).transpose(1, 2)\n",
    "        return Q, K, V\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, latent_dim, to_dim):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(latent_dim, to_dim)\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size, n_heads, to_num, d_in = Q.shape\n",
    "        attn = self.softmax(Q @ K.transpose(2,3) / d_in)\n",
    "        out = attn @ V\n",
    "        out = self.out(out.transpose(1, 2).reshape(batch_size, to_num, n_heads*d_in))\n",
    "        return out, attn\n",
    "class SkipLayerNorm(nn.Module):\n",
    "    def __init__(self, to_len, to_dim):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((to_len, to_dim))\n",
    "    def forward(self, x_0, x_1):\n",
    "        return self.layer_norm(x_0+x_1)\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, to_dim, hidden_dim, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(to_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, to_dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.FFN(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd6a21",
   "metadata": {},
   "source": [
    "Now, we can build the TransformerBlock thanks to the TensorDictModule. Since the changes affect the tensor dict, we just need to map outputs to the right name such as it is picked up by the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b52dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockTensorDict(nn.Module):\n",
    "    def __init__(self, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer_block = nn.Sequential(\n",
    "            TensorDictModule(TokensToQKV(to_dim, from_dim, latent_dim), in_keys=[to_name, from_name], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(SplitHeads(num_heads), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"Q\", \"K\", \"V\"]),\n",
    "            TensorDictModule(Attention(latent_dim, to_dim), in_keys=[\"Q\", \"K\", \"V\"], out_keys=[\"X_out\",\"Attn\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "            TensorDictModule(FFN(to_dim, 4*to_dim), in_keys=[\"X_to\"], out_keys=[\"X_out\"]),\n",
    "            TensorDictModule(SkipLayerNorm(to_len, to_dim), in_keys=[\"X_to\", \"X_out\"], out_keys=[\"X_to\"]),\n",
    "        )\n",
    "    def forward(self, X_tensor_dict):\n",
    "        self.transformer_block(X_tensor_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aa84439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        Attn: Tensor(torch.Size([8, 2, 3, 10]), dtype=torch.float32),\n",
       "        K: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        Q: Tensor(torch.Size([8, 2, 3, 5]), dtype=torch.float32),\n",
       "        V: Tensor(torch.Size([8, 2, 10, 5]), dtype=torch.float32),\n",
       "        X_from: Tensor(torch.Size([8, 10, 6]), dtype=torch.float32),\n",
       "        X_out: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32),\n",
       "        X_to: Tensor(torch.Size([8, 3, 5]), dtype=torch.float32)},\n",
       "    batch_size=torch.Size([8]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "transformer_block = TransformerBlockTensorDict(\"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_block(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f125e",
   "metadata": {},
   "source": [
    "The output of the transformer layer can now be found at tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31bc9d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8713, -1.2626,  1.3218, -0.2947,  1.6938],\n",
       "         [-0.7374, -0.6038, -1.4958, -0.3975,  0.0741],\n",
       "         [-0.5026,  0.0095,  1.8102,  0.2308,  1.0256]],\n",
       "\n",
       "        [[ 0.4484,  0.0689,  1.0152, -1.1690,  1.2264],\n",
       "         [-0.5891,  0.0737,  0.7038,  1.0404,  0.0131],\n",
       "         [ 1.0050, -2.4708, -0.7890, -1.0160,  0.4391]],\n",
       "\n",
       "        [[-1.8364, -0.5181, -0.5258,  0.5166,  1.8120],\n",
       "         [ 1.3389,  0.1451, -0.1267, -0.7637,  1.6104],\n",
       "         [-0.1859, -0.4134, -1.4359, -0.1131,  0.4961]],\n",
       "\n",
       "        [[-1.0511,  0.1636, -0.9440, -0.2152, -0.4874],\n",
       "         [ 1.4676,  2.0405,  0.2846,  0.5990,  1.0199],\n",
       "         [-1.5073,  0.0980, -1.5943, -0.1160,  0.2421]],\n",
       "\n",
       "        [[-0.6059,  0.3442,  0.6854, -0.0933,  1.8850],\n",
       "         [-0.2040, -2.0479,  0.8991,  1.1162,  0.0855],\n",
       "         [-1.6792, -0.4797,  0.4558,  0.4763, -0.8374]],\n",
       "\n",
       "        [[-1.2463, -1.3887,  1.2930,  0.5651,  0.9994],\n",
       "         [-0.1023, -0.4523, -2.0760,  1.6500,  0.5962],\n",
       "         [ 0.7221,  0.1171,  0.1437, -0.2839, -0.5374]],\n",
       "\n",
       "        [[-0.3637, -1.2232, -2.0972, -0.7830, -0.1663],\n",
       "         [-0.5369,  0.0789, -0.9869,  0.6352,  1.5502],\n",
       "         [ 0.3313,  0.2594,  1.5771,  0.6336,  1.0914]],\n",
       "\n",
       "        [[-1.0102,  0.4594,  0.5603,  0.1587,  0.2164],\n",
       "         [-1.3799, -0.1682, -1.9153,  0.9154,  1.8860],\n",
       "         [-0.0694, -0.8951, -0.6851,  0.6067,  1.3203]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e6820",
   "metadata": {},
   "source": [
    "We can now create a transformer easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "928bcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTensorDict(nn.Module):\n",
    "    def __init__(self, num_blocks, to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.ModuleList([TransformerBlockTensorDict(to_name, from_name, to_dim, to_len, from_dim, latent_dim, num_heads) for _ in range(num_blocks)])\n",
    "    def forward(self, X_tensor_dict):\n",
    "        for transformer_block in self.transformer:\n",
    "            transformer_block(X_tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d672d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dim = 5\n",
    "from_dim = 6\n",
    "latent_dim = 10\n",
    "to_len = 3\n",
    "from_len = 10\n",
    "batch_size = 8\n",
    "num_heads = 2\n",
    "\n",
    "tokens = TensorDict({\"X_to\":torch.randn(batch_size, to_len, to_dim), \"X_from\":torch.randn(batch_size, from_len, from_dim)}, batch_size=[batch_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522bd3a",
   "metadata": {},
   "source": [
    "For an encoder, we just need to take the same tokens for both queries, keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f51e79cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.0456e-01,  6.2688e-01, -1.1026e+00,  2.2786e-02, -4.8655e-02],\n",
       "         [-9.7513e-01,  1.4375e+00,  9.4504e-01,  2.0078e+00, -8.5485e-01],\n",
       "         [-1.3192e+00,  8.7940e-01, -1.2088e+00,  4.6428e-01, -1.7003e-01]],\n",
       "\n",
       "        [[-2.4683e+00,  1.1900e+00, -4.6999e-01,  8.1202e-01, -1.0019e+00],\n",
       "         [ 9.6744e-01,  1.0676e+00,  1.0292e+00,  4.7986e-01, -1.2177e+00],\n",
       "         [ 3.2124e-02,  4.6237e-01, -7.1896e-01,  2.0720e-03, -1.6574e-01]],\n",
       "\n",
       "        [[-2.2703e-01,  1.5631e+00,  1.1274e+00,  8.1163e-02, -1.5204e+00],\n",
       "         [-1.8939e+00,  7.4907e-01, -1.6144e+00,  7.3381e-01,  7.8596e-01],\n",
       "         [-7.7463e-02,  2.4682e-01,  4.6115e-01,  3.5791e-01, -7.7312e-01]],\n",
       "\n",
       "        [[ 4.2789e-01,  7.7004e-02, -5.2232e-01, -1.3905e+00, -6.8685e-01],\n",
       "         [-9.8940e-01,  6.9261e-02,  1.8176e+00,  1.2323e+00, -2.8591e-01],\n",
       "         [-1.9008e+00,  1.2424e+00,  9.0587e-01,  3.6788e-01, -3.6444e-01]],\n",
       "\n",
       "        [[ 1.4538e+00,  4.6922e-01, -8.1502e-01, -3.0426e-01,  3.3914e-01],\n",
       "         [ 4.5448e-02,  5.8241e-01, -5.1411e-02,  2.1194e-01, -3.5672e-01],\n",
       "         [-2.6675e+00,  1.0907e+00,  9.3493e-01,  4.4590e-01, -1.3785e+00]],\n",
       "\n",
       "        [[-8.6485e-01,  1.1146e+00, -9.4181e-02, -1.1407e-01,  6.2847e-01],\n",
       "         [-9.5162e-01,  1.4542e+00,  1.2157e-02, -2.0240e-01, -1.5317e+00],\n",
       "         [-9.3001e-01,  9.8748e-01,  9.6898e-01,  1.2264e+00, -1.7035e+00]],\n",
       "\n",
       "        [[ 1.8318e-01,  8.8817e-01, -4.1605e-01, -7.2077e-02,  1.0248e+00],\n",
       "         [ 1.1950e+00, -3.1990e-01, -3.0087e+00, -8.1052e-01,  4.2547e-01],\n",
       "         [ 4.8264e-02,  8.2594e-01, -4.8231e-01, -2.2883e-01,  7.4760e-01]],\n",
       "\n",
       "        [[-2.0185e+00,  2.7137e-01,  1.9260e-01, -3.7461e-01, -1.4131e+00],\n",
       "         [ 3.0497e-01,  4.7218e-01,  1.4051e+00, -7.2168e-01, -7.7026e-01],\n",
       "         [ 1.3967e+00, -6.0792e-01,  1.1108e-01,  1.7145e+00,  3.7664e-02]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder = TransformerTensorDict(6, \"X_to\", \"X_to\", to_dim, to_len, to_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_encoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd013d3",
   "metadata": {},
   "source": [
    "For a decoder, we now can extract info from X_from into X_to. X_to will map to queries whereas X_from will map to keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21d299fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3380,  0.7571, -1.0049,  0.7433, -0.1268],\n",
       "         [-1.2908,  1.1133, -0.1441,  1.9060, -1.1740],\n",
       "         [-1.2169,  1.1862, -0.9880,  0.9077, -0.3301]],\n",
       "\n",
       "        [[-0.9989,  1.0225,  0.0516,  1.4268, -1.3924],\n",
       "         [-0.4546,  1.6237, -0.9002,  1.0320, -1.1606],\n",
       "         [-0.5801,  0.9752, -1.1864,  0.4610,  0.0803]],\n",
       "\n",
       "        [[-0.9055,  1.3019, -0.1604,  1.2191, -1.8533],\n",
       "         [-1.2209,  1.0449, -0.6953,  1.0392,  0.4056],\n",
       "         [-0.3828,  0.6094,  0.0309,  0.9272, -1.3600]],\n",
       "\n",
       "        [[-0.3067,  0.0189, -0.9604, -0.3966, -0.3716],\n",
       "         [-1.0679,  0.4198,  1.2470,  1.9662, -0.8475],\n",
       "         [-1.6165,  1.1001, -0.3376,  1.4791, -0.3264]],\n",
       "\n",
       "        [[-0.0980,  0.6583, -1.2214,  0.2261, -0.4485],\n",
       "         [-0.6073,  1.5547, -0.3092,  1.1512, -1.0601],\n",
       "         [-1.4279,  1.2677,  0.1266,  1.4727, -1.2850]],\n",
       "\n",
       "        [[-0.4164,  0.7499,  0.2536,  0.1846,  0.1112],\n",
       "         [-0.4129,  1.0208, -0.3762,  0.7487, -1.3215],\n",
       "         [-0.1598,  0.5029, -0.3288,  1.9525, -2.5087]],\n",
       "\n",
       "        [[-0.3682,  0.8304, -0.8471,  0.5485,  0.4438],\n",
       "         [-0.8762,  1.1699, -2.6552,  0.4682,  0.1896],\n",
       "         [-0.3391,  1.0842, -1.0764,  0.5564,  0.8712]],\n",
       "\n",
       "        [[-1.0284,  0.3804,  0.4793,  0.4096, -2.1200],\n",
       "         [-0.2695,  1.0064, -0.2066,  0.1593, -0.7439],\n",
       "         [ 0.9516,  0.8927, -0.9734,  1.9427, -0.8802]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder = TransformerTensorDict(6, \"X_to\", \"X_from\", to_dim, to_len, from_dim, latent_dim, num_heads)\n",
    "\n",
    "transformer_decoder(tokens)\n",
    "tokens[\"X_to\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6483e4f",
   "metadata": {},
   "source": [
    "Now we can look at both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5548e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=5, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_to'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af5a02ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTensorDict(\n",
       "  (transformer): ModuleList(\n",
       "    (0): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlockTensorDict(\n",
       "      (transformer_block): Sequential(\n",
       "        (0): TensorDictModule(\n",
       "            module=TokensToQKV(\n",
       "              (q): Linear(in_features=5, out_features=10, bias=True)\n",
       "              (k): Linear(in_features=6, out_features=10, bias=True)\n",
       "              (v): Linear(in_features=6, out_features=10, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_from'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (1): TensorDictModule(\n",
       "            module=SplitHeads(), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['Q', 'K', 'V'])\n",
       "        (2): TensorDictModule(\n",
       "            module=Attention(\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (out): Linear(in_features=10, out_features=5, bias=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['Q', 'K', 'V'], \n",
       "            out_keys=['X_out', 'Attn'])\n",
       "        (3): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "        (4): TensorDictModule(\n",
       "            module=FFN(\n",
       "              (FFN): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=20, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "                (3): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to'], \n",
       "            out_keys=['X_out'])\n",
       "        (5): TensorDictModule(\n",
       "            module=SkipLayerNorm(\n",
       "              (layer_norm): LayerNorm((3, 5), eps=1e-05, elementwise_affine=True)\n",
       "            ), \n",
       "            device=cpu, \n",
       "            in_keys=['X_to', 'X_out'], \n",
       "            out_keys=['X_to'])\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec2070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
